#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Nov 29 14:02:42 2023

@author: kiesli21
"""
from pmma.cmd_args import feature_ranking_parser
from pmma.familiar_preparation import create_familiar_r_file, create_feature_table_for_familiar, perform_familiar_experiment
import shutil
import os
import pandas as pd
import json
import subprocess
import matplotlib.pyplot as plt

def plot_feature_importance(data, save_path, feature_type, feature_selection_method):
    """
    Plots a bar plot of feature importance based on the provided data for a single feature selection method.

    Args:
    data (DataFrame): A pandas DataFrame containing the columns 'name' and 'score'.
    save_path (str): The file path where the plot will be saved.
    feature_type (str): Type pf the features for the plot title.
    feature_selection_method (str). Feature selection method used to determine feature importance.

    The function does not return anything but saves the plot at the specified location.
    """

    # Sorting data by score
    sorted_data = data.sort_values(by='score', ascending=False)

    # Adjusting the size of x-ticks based on the number of features
    tick_size = max(min(10, 120 / len(sorted_data)), 6)

    # Creating the bar plot
    plt.figure(figsize=(10, 6))
    plt.bar(sorted_data['feature'], sorted_data['score'], align='center')
    plt.xticks(rotation=90, fontsize=tick_size)
    plt.xlabel('Feature')
    plt.ylabel('Importance Score')
    plt.title(f'{feature_type} Feature Importance using {feature_selection_method} Method')
    plt.xlim(-0.5, len(sorted_data) - 0.5) # Set limits to start with the first bar
    plt.grid(False) # Disable the grid

    # Adjust layout to ensure x-ticks are not cut off
    plt.tight_layout()

    plot_dir = os.path.dirname(save_path)
    # Create these directories if they do not exist
    os.makedirs(plot_dir, exist_ok=True)

    # Saving the plot
    plt.savefig(save_path, dpi = 300)
    plt.close()


def get_feature_ranking(feature_ranking_file_path, experiment_dir):
    """
    Retrieves the feature ranking from the familiar feature ranking process.

    This function accesses the generated feature ranking file, reads it, and then exports the relevant data to a specified path.

    Parameters:
    - feature_ranking_path (str): The path where the feature ranking was performed.
    - feature_ranking_file_path (str): The path to save the feature ranking results.
    - feature_type (str): The type of feature that was selected.
    - feature_selection_method (str): The method used for feature selection.

    Returns:
    None
    """
    
    # Path to the feature ranking file generated by the familiar process
    familiar_feature_ranking_file_path = os.path.join(experiment_dir, "results/pooled_data/variable_importance/variable_importance_feature_selection_stability.csv")
    
    # Ensure that the feature ranking file exists
    assert os.path.isfile(familiar_feature_ranking_file_path), f"Feature ranking file does not exist here {familiar_feature_ranking_file_path}!"
    
    # Read the feature ranking data from the file
    feature_ranking = pd.read_csv(familiar_feature_ranking_file_path, sep = ";")
    
    # Selecting only the necessary columns: feature, rank, and score
    feature_ranking = feature_ranking[["name", "rank", "score"]]
    
    feature_ranking.rename(columns = {"name": "feature"}, inplace = True)
    
    feature_ranking_dir = os.path.dirname(feature_ranking_file_path)

    # Create these directories if they do not exist
    os.makedirs(feature_ranking_dir, exist_ok=True)
    
    # Saving the processed feature ranking data to the specified path
    feature_ranking.to_csv(feature_ranking_file_path, index = False, sep = ";")
    
    print(f"Feature ranking file saved to {feature_ranking_file_path}!")
    
    return feature_ranking
  

if __name__ == "__main__":
    # Parse command line arguments for feature ranking
    parser = feature_ranking_parser("Feature ranking")
    args = parser.parse_args()
    
    print("Start feature ranking.....")

    # Read the JSON file containing feature clustering metadata
    with open(args.feature_clustering_metadata_file_path, 'r') as file:
        cluster_metadata = json.load(file)

    # Extract 'cluster_representatives' from the metadata
    cluster_representatives = cluster_metadata.get('cluster_representatives', [])
    
    # Define and create a temporary directory for data processing
    temp_data_dir = os.path.join(args.feature_ranking_path, "temp_data")
    os.makedirs(temp_data_dir, exist_ok=True)
    
    # Construct the path for the cluster feature file
    cluster_feature_file_path = os.path.join(temp_data_dir, f"features_{args.feature_type}_{args.feature_selection_method}.csv")
    
    data_table = pd.read_csv(args.data_table_path, sep = ";")
    
    feature_table = pd.read_csv(args.feature_file_path, sep = ";")
    
    # Create a feature table based on the provided parameters
    create_feature_table_for_familiar(data_table, feature_table, cluster_representatives, cluster_feature_file_path)
    
    # Construct the path for the familiar R script file
    familiar_r_file_path = os.path.join(args.feature_ranking_path, f"familiar/r_files/R_file_{args.feature_type}_{args.feature_selection_method}.R")
    
    
    experiment_dir = os.path.join(args.feature_ranking_path, "familiar", "experiments", args.feature_type, f"{args.feature_selection_method}")
    
    perform_familiar_experiment(
    feature_file_path=cluster_feature_file_path,
    model_learner="glm_gaussian",
    experiment_dir=experiment_dir,
    familiar_r_file_path=familiar_r_file_path,
    experimental_design="bs(fs,20) + mb",
    batch_id_column="cohort",
    sample_id_column="id_global",
    development_batch_id="training",
    validation_batch_id="validation",
    outcome_name="range_shift",
    outcome_column="range_shift",
    outcome_type="continuous",
    parallel_nr_cores=1,  # Or directly use multiprocessing.cpu_count() for parallel execution
    parallel=True,
    feature_max_fraction_missing=0.01,
    filter_method="none",
    transformation_method="yeo_johnson",
    normalisation_method="standardisation",
    cluster_method="none",
    parallel_preprocessing="parallel_preprocessing",
    fs_method=args.feature_selection_method,  # Replace with the actual method used for feature selection
    vimp_aggregation_method="enhanced_borda",
    vimp_aggregation_rank_threshold=10,
    novelty_detector="none",
    optimisation_determine_vimp=True,
    evaluation_metric=["rmse", "r2_score"],
    imputation_method="simple",
    hyperparameter={"glm_gaussian": {"sign_size": len(["feature1", "feature2", "feature3"])}},  # Adjust "sign_size" based on the number of features
    skip_evaluation_elements=["auc_data", "calibration_data", "calibration_info", "confusion_matrix", "feature_similarity",
                              "decision_curve_analyis", "ice_data", "permutation_vimp", "univariate_analysis", "model_vimp", "model_performance", "feature_expressions",
                              "hyperparameters", "prediction_data"],
    smbo_stop_convergent_iterations=1
    )

    
    # Retrieve and process the feature ranking results
    feature_ranking = get_feature_ranking(args.feature_ranking_file_path, experiment_dir)
    
    plot_feature_importance(feature_ranking, args.feature_importance_plot_path, args.feature_type, args.feature_selection_method)
    
    
    