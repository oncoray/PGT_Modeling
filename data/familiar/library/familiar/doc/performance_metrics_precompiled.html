<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Alex Zwanenburg" />

<meta name="date" content="2022-12-16" />

<title>Performance metrics</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<img src="data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   version="1.1"
   id="Layer_1"
   x="0px"
   y="0px"
   viewBox="0 0 735 852"
   style="enable-background:new 0 0 735 852;"
   xml:space="preserve"
   sodipodi:docname="familiar.svg"
   inkscape:version="1.0.1 (3bc2e813f5, 2020-09-07)"><metadata
   id="metadata79"><rdf:RDF><cc:Work
       rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type
         rdf:resource="http://purl.org/dc/dcmitype/StillImage" /></cc:Work></rdf:RDF></metadata><defs
   id="defs77"><clipPath
     clipPathUnits="userSpaceOnUse"
     id="clipPath1261"><path
       class="st0"
       d="M 18.2,626.4 V 223.1 L 69.8,193.3 367.5,21.5 v 0 l 296.7,171.3 52.6,30.3 V 626.4 L 367.5,828 Z"
       id="path1263"
       style="display:inline;fill:#ffd5e5" /></clipPath></defs><sodipodi:namedview
   pagecolor="#ffffff"
   bordercolor="#666666"
   borderopacity="1"
   objecttolerance="10"
   gridtolerance="10"
   guidetolerance="10"
   inkscape:pageopacity="0"
   inkscape:pageshadow="2"
   inkscape:window-width="2489"
   inkscape:window-height="1289"
   id="namedview75"
   showgrid="false"
   inkscape:zoom="0.70539906"
   inkscape:cx="455.24253"
   inkscape:cy="60.680079"
   inkscape:window-x="0"
   inkscape:window-y="0"
   inkscape:window-maximized="0"
   inkscape:current-layer="layer2" />
<style
   type="text/css"
   id="style2">
	.st0{fill:#144F85;}
	.st1{fill:#173E6C;}
	.st2{fill:#E6B35A;}
	.st3{fill:#FFFFFF;}
	.st4{fill:#231F20;}
</style>
<g
   inkscape:groupmode="layer"
   id="layer3"
   inkscape:label="Hexagon"
   style="display:inline"><path
     class="st0"
     d="M 18.2,626.4 V 223.1 L 69.8,193.3 367.5,21.5 v 0 l 296.7,171.3 52.6,30.3 V 626.4 L 367.5,828 Z"
     id="path4"
     style="fill:#ffd5e5" /><path
     class="st1"
     d="M 705.6,196.2 427.8,35.8 367.5,1 307.2,35.8 29.4,196.2 0.1,213.1 v 424.2 l 29.3,16.9 281.3,162.4 56.9,32.8 56.9,-32.8 281.3,-162.4 29.3,-16.9 V 213.1 Z m 0,425.3 L 367.5,816.7 29.4,621.5 V 231 L 367.5,35.8 v 0 L 705.6,231 Z"
     id="path8"
     style="fill:#ffaacc" /></g><g
   inkscape:groupmode="layer"
   id="layer2"
   inkscape:label="NetworkBG"><g
     id="g1203"
     clip-path="url(#clipPath1261)"><path
       style="fill:#ffeeaa;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 604.82727,123.80744 368.81604,260.06859 298.81945,261.12628 1.0461121,433.04579 29.3512,482.21648 327.12453,310.29697 397.12112,309.23928 633.13236,172.97813 Z"
       id="path1032-8"
       sodipodi:nodetypes="ccccccccc" /><path
       style="fill:#ffeeaa;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 524.66016,-15.335647 288.64893,120.9255 218.65234,121.98319 -79.120987,293.9027 -50.815883,343.07338 246.95744,171.15387 316.95403,170.09618 552.96527,33.835032 Z"
       id="path1032-8-8"
       sodipodi:nodetypes="ccccccccc" /><path
       style="fill:#ffdd55;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
       d="M 552.96527,33.835032 316.95403,170.09618 246.95744,171.15387 -50.815883,343.07338 1.0461121,433.04579 298.81944,261.12628 368.81603,260.06859 604.82726,123.80744 Z"
       id="path1032-8-8-7"
       sodipodi:nodetypes="ccccccccc" /></g><path
     class="st1"
     d="M 705.6,196.2 427.8,35.8 367.5,1 307.2,35.8 29.4,196.2 0.1,213.1 v 424.2 l 29.3,16.9 281.3,162.4 56.9,32.8 56.9,-32.8 281.3,-162.4 29.3,-16.9 V 213.1 Z m 0,425.3 L 367.5,816.7 29.4,621.5 V 231 L 367.5,35.8 v 0 L 705.6,231 Z"
     id="path8-4"
     style="display:inline;fill:#ffaacc" /><path
     sodipodi:type="star"
     style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none"
     id="path1013-0"
     sodipodi:sides="5"
     sodipodi:cx="593.43592"
     sodipodi:cy="273.58523"
     sodipodi:r1="43.422688"
     sodipodi:r2="21.711344"
     sodipodi:arg1="0.62879629"
     sodipodi:arg2="1.2571148"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 628.55341,299.12523 -28.41819,-4.88808 -20.13738,20.6391 -4.13287,-28.5378 -25.85174,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43055,25.5168 z"
     inkscape:transform-center-x="4.1403908"
     inkscape:transform-center-y="-0.0063989586" /><path
     sodipodi:type="star"
     style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none"
     id="path1013-0-5"
     sodipodi:sides="5"
     sodipodi:cx="659.08881"
     sodipodi:cy="357.25101"
     sodipodi:r1="43.422688"
     sodipodi:r2="21.711344"
     sodipodi:arg1="0.62879629"
     sodipodi:arg2="1.2571148"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 694.2063,382.791 -28.41819,-4.88808 -20.13738,20.6391 -4.13286,-28.5378 -25.85175,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43054,25.5168 z"
     inkscape:transform-center-x="-2.3762241"
     inkscape:transform-center-y="-0.19639333"
     transform="matrix(0.50883698,0.35123436,-0.35123436,0.50883698,437.9071,-51.238505)" /><path
     sodipodi:type="star"
     style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none"
     id="path1013-0-5-4"
     sodipodi:sides="5"
     sodipodi:cx="659.08881"
     sodipodi:cy="357.25101"
     sodipodi:r1="43.422688"
     sodipodi:r2="21.711344"
     sodipodi:arg1="0.62879629"
     sodipodi:arg2="1.2571148"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 694.2063,382.791 -28.41819,-4.88808 -20.13738,20.6391 -4.13286,-28.5378 -25.85175,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43054,25.5168 z"
     inkscape:transform-center-x="-2.3762241"
     inkscape:transform-center-y="-0.19639333"
     transform="matrix(0.50883698,0.35123436,-0.35123436,0.50883698,458.27634,-128.13567)" /></g><g
   inkscape:groupmode="layer"
   id="layer1"
   inkscape:label="Familiar"
   style="display:inline"
   sodipodi:insensitive="true"><path
     id="rect1265"
     style="fill:#ffd5e5;stroke:none;stroke-width:0.888669;stroke-linecap:round;stroke-linejoin:round"
     d="m 245.46055,257.17563 229.95737,-15.59401 25.54911,67.75725 -0.0316,100.16657 -113.21601,42.22457 -148.63819,-42.93339 z"
     sodipodi:nodetypes="ccccccc" /><path
     style="fill:#d40055;stroke:none;stroke-width:3.16295"
     d="m 196.18676,315.6231 c -10.63253,17.38577 -33.64223,11.64186 -43.00737,28.79103 -36.61508,67.04939 17.43539,145.00334 62.13877,186.97879 17.5006,16.4315 42.7508,54.66573 50.734,46.89383 7.9832,-7.7719 -15.8147,-44.28123 -15.8147,-44.28123 28.2966,-20.2857 82.299,43.82139 86.6834,19.30534 4.3845,-24.51606 -46.8635,-18.95742 -67.7058,-44.60891 18.3594,0.003 59.6957,1.2462 63.2589,-9.48884 3.5633,-10.73504 -72.7477,-12.65178 -72.7477,-12.65178 v -9.48883 c 34.0706,-9.2959 57.6399,0.0886 91.7254,-0.81921 40.6388,-1.08172 68.0795,-15.63444 104.3772,7.1451 -25.2055,6.06969 -72.3313,25.48918 -69.5848,31.62945 2.7465,6.14027 72.7477,-3.16294 72.7477,-3.16294 0,0 -57.9896,56.7778 -37.9553,63.25891 20.0343,6.48111 47.0025,-53.26957 69.2495,-46.34981 18.3641,5.25049 12.4794,48.94683 25.6389,46.34981 13.1595,-2.59702 -1.3633,-35.41234 4.7665,-53.77008 15.9318,-47.71619 71.4573,-124.46633 44.8348,-177.06643 -9.8589,-19.48185 -35.2004,-18.55479 -45.9956,-38.02841 -10.0929,-18.20718 -8.0181,-37.2576 -22.925,-53.74319 -34.35974,-24.66838 -39.39345,-40.50377 -107.1986,-44.29358 0,0 -79.32687,1.91436 -115.39694,20.37701 -36.07006,18.46265 -63.11016,62.96566 -77.82326,87.02397 z m 288.1086,-44.14206 c -31.1126,3.20944 -51.2432,56.52436 -12.6391,55.74438 9.2389,-0.18661 17.684,-6.95247 25.2909,-11.46315 14.9228,44.08514 -20.2808,63.4528 -60.096,71.8422 -66.9715,14.1118 -129.6121,21.60703 -189.7767,-18.07212 4.9516,-26.65573 -6.3679,-90.45044 15.8758,-103.05699 11.5245,-6.53148 25.0878,-7.94627 37.6087,-3.39226 16.6016,6.03838 24.9053,24.81679 41.4064,32.38129 36.5393,16.75032 91.7428,-5.26188 88.5599,-49.28692 22.9719,0 49.3293,-3.21766 53.7701,25.30357 m -205.2498,18.1746 c -31.0111,12.78146 -7.1581,66.184 24.286,52.66209 29.17,-12.54392 6.5498,-65.37112 -24.286,-52.66209 m 132.5021,41.92136 0.8771,11.7139 8.3914,-0.0645 -1.0516,-13.03381 -8.2169,1.38445 m -50.6071,3.16295 3.1629,12.65178 h 6.3259 l 3.1629,-12.65178 h -12.6517 m 142.3325,50.60712 c -51.7831,62.49348 -152.6773,51.3441 -221.4062,34.79241 0,0 79.3233,3.56324 116.6478,-2.66733 37.3245,-6.23056 104.7584,-32.12508 104.7584,-32.12508 m -53.7701,75.9107 c 7.8662,-5.63637 54.0041,-39.90056 58.1855,-37.39867 10.656,6.37966 -2.9763,25.22449 -8.2552,30.35163 -13.2433,12.85737 -33.4608,11.91481 -49.9303,7.04704 m -192.9396,-6.32589 v 6.32589 c -22.296,10.71289 -35.7552,2.09071 -37.9554,-22.14062 z"
     id="path988"
     sodipodi:nodetypes="scczczczcccczczczccscczscscccssscccsccccccccccccczccccccccc" /><text
     xml:space="preserve"
     style="font-size:106.667px;line-height:1.25;font-family:Bahnschrift;-inkscape-font-specification:Bahnschrift;fill:#ffffff"
     x="133.01973"
     y="669.02026"
     id="text1007"><tspan
       sodipodi:role="line"
       id="tspan1005"
       x="133.01973"
       y="669.02026"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:106.667px;font-family:'Lucida Sans';-inkscape-font-specification:'Lucida Sans';fill:#ffffff">FAMILIAR</tspan></text><path
     style="fill:#ffaacc;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1"
     d="M 362.57822,85.512104 311.7313,246.86829 c 0,0 25.2203,31.68457 54.88255,30.82445 36.78744,-1.06673 54.26709,-35.12035 54.26709,-35.12035 z"
     id="path1009"
     sodipodi:nodetypes="ccscc" /><path
     sodipodi:type="star"
     style="fill:#ffe680;stroke:none;stroke-width:0.463344;stroke-linecap:round;stroke-linejoin:round"
     id="path1011"
     sodipodi:sides="5"
     sodipodi:cx="393.43726"
     sodipodi:cy="240.33679"
     sodipodi:r1="21.630606"
     sodipodi:r2="10.815303"
     sodipodi:arg1="1.300471"
     sodipodi:arg2="1.9287895"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 399.2136,261.18186 -9.56598,-10.71543 -14.25022,1.80547 7.23494,-12.40903 -6.12067,-12.99484 14.03741,3.04623 10.46744,-9.83673 1.44066,14.29171 12.5899,6.9154 -13.14703,5.78653 z"
     inkscape:transform-center-x="-1.7849856"
     inkscape:transform-center-y="0.29290531" /><path
     sodipodi:type="star"
     style="fill:#ffe680;stroke:none;stroke-width:0.552007;stroke-linecap:round;stroke-linejoin:round"
     id="path1013"
     sodipodi:sides="5"
     sodipodi:cx="365.95331"
     sodipodi:cy="171.80791"
     sodipodi:r1="24.417637"
     sodipodi:r2="12.208818"
     sodipodi:arg1="0.62879629"
     sodipodi:arg2="1.2571148"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 385.70073,186.16967 -15.98024,-2.74869 -11.32374,11.60587 -2.32401,-16.0475 -14.53707,-7.18311 14.54393,-7.16921 2.33934,-16.04528 11.31265,11.61668 15.98286,-2.73341 -7.55232,14.34872 z"
     inkscape:transform-center-x="2.3282526"
     inkscape:transform-center-y="-0.0036080646" /><path
     sodipodi:type="star"
     style="display:inline;fill:#ffe680;stroke:none;stroke-width:0.440145;stroke-linecap:round;stroke-linejoin:round"
     id="path1011-6"
     sodipodi:sides="5"
     sodipodi:cx="344.4216"
     sodipodi:cy="225.49474"
     sodipodi:r1="20.547558"
     sodipodi:r2="10.273779"
     sodipodi:arg1="1.300471"
     sodipodi:arg2="1.9287895"
     inkscape:flatsided="false"
     inkscape:rounded="0"
     inkscape:randomized="0"
     d="m 349.90872,245.29609 -9.087,-10.17891 -13.53671,1.71507 6.87268,-11.78771 -5.81421,-12.34419 13.33456,2.89371 9.94333,-9.34421 1.36853,13.57613 11.95952,6.56915 -12.48876,5.4968 z"
     inkscape:transform-center-x="-1.6956102"
     inkscape:transform-center-y="0.27822403" /></g>
<title
   id="title6">feather</title>

































</svg>
" align="right" width="120" />

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>






<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Performance metrics</h1>
<h4 class="author">Alex Zwanenburg</h4>
<h4 class="date">2022-12-16</h4>


<div id="TOC">
<ul>
<li><a href="#categorical-outcomes" id="toc-categorical-outcomes">Categorical outcomes</a>
<ul>
<li><a href="#area-under-the-receiver-operating-curve" id="toc-area-under-the-receiver-operating-curve">Area under the
receiver-operating curve</a></li>
<li><a href="#brier-score" id="toc-brier-score">Brier score</a></li>
<li><a href="#contingency-table-based-metrics" id="toc-contingency-table-based-metrics">Contingency table-based
metrics</a>
<ul>
<li><a href="#accuracy" id="toc-accuracy">Accuracy</a></li>
<li><a href="#balanced-accuracy" id="toc-balanced-accuracy">Balanced
accuracy</a></li>
<li><a href="#balanced-error-rate" id="toc-balanced-error-rate">Balanced
error rate</a></li>
<li><a href="#f1-score" id="toc-f1-score">F1 score</a></li>
<li><a href="#false-discovery-rate" id="toc-false-discovery-rate">False
discovery rate</a></li>
<li><a href="#informedness" id="toc-informedness">Informedness</a></li>
<li><a href="#cohens-kappa" id="toc-cohens-kappa">Cohen’s kappa</a></li>
<li><a href="#markedness" id="toc-markedness">Markedness</a></li>
<li><a href="#matthews-correlation-efficient" id="toc-matthews-correlation-efficient">Matthews correlation
efficient</a></li>
<li><a href="#negative-predictive-value" id="toc-negative-predictive-value">Negative predictive value</a></li>
<li><a href="#positive-predictive-value" id="toc-positive-predictive-value">Positive predictive value</a></li>
<li><a href="#recall" id="toc-recall">Recall</a></li>
<li><a href="#specificity" id="toc-specificity">Specificity</a></li>
<li><a href="#youdens-j-statistic" id="toc-youdens-j-statistic">Youden’s
J statistic</a></li>
</ul></li>
</ul></li>
<li><a href="#regression-outcomes" id="toc-regression-outcomes">Regression outcomes</a>
<ul>
<li><a href="#explained-variance" id="toc-explained-variance">Explained
variance</a></li>
<li><a href="#mean-absolute-error" id="toc-mean-absolute-error">Mean
absolute error</a></li>
<li><a href="#relative-absolute-error" id="toc-relative-absolute-error">Relative absolute error</a></li>
<li><a href="#mean-log-absolute-error" id="toc-mean-log-absolute-error">Mean log absolute error</a></li>
<li><a href="#mean-squared-error" id="toc-mean-squared-error">Mean
squared error</a></li>
<li><a href="#relative-squared-error" id="toc-relative-squared-error">Relative squared error</a></li>
<li><a href="#mean-squared-log-error" id="toc-mean-squared-log-error">Mean squared log error</a></li>
<li><a href="#median-absolute-error" id="toc-median-absolute-error">Median absolute error</a></li>
<li><a href="#r2-score" id="toc-r2-score">R<sup>2</sup> score</a></li>
<li><a href="#root-mean-square-error" id="toc-root-mean-square-error">Root mean square error</a></li>
<li><a href="#root-relative-squared-error" id="toc-root-relative-squared-error">Root relative squared
error</a></li>
<li><a href="#root-mean-square-log-error" id="toc-root-mean-square-log-error">Root mean square log error</a></li>
</ul></li>
<li><a href="#survival-outcomes" id="toc-survival-outcomes">Survival
outcomes</a>
<ul>
<li><a href="#concordance-index" id="toc-concordance-index">Concordance
index</a></li>
</ul></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<p>When we train a model, we usually want to know how good the model is.
Model performance is assessed using different metrics that quantify how
well a model discriminates cases, stratifies groups or predicts values.
<code>familiar</code> implements metrics that are typically used to
assess the performance of categorical, regression and survival
models.</p>
<div id="categorical-outcomes" class="section level1">
<h1>Categorical outcomes</h1>
<p>Performance metrics for models with categorical outcomes,
i.e. <code>binomial</code> and <code>multinomial</code> are listed
below.</p>
<table>
<caption>Overview of performance metrics for categorical outcomes. Some
contingency table-based metrics require averaging for
<code>multinomial</code> outcomes as their original definition only
covers <code>binomial</code> problems with two classes.</caption>
<colgroup>
<col width="37%" />
<col width="49%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>method</strong></th>
<th align="left"><strong>tag</strong></th>
<th align="center"><strong>averaging</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">accuracy</td>
<td align="left"><code>accuracy</code></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">area under the receiver-operating curve</td>
<td align="left"><code>auc</code>, <code>auc_roc</code></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">balanced accuracy</td>
<td align="left"><code>bac</code>, <code>balanced_accuracy</code></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">balanced error rate</td>
<td align="left"><code>ber</code>, <code>balanced_error_rate</code></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">Brier score</td>
<td align="left"><code>brier</code></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">Cohen’s kappa</td>
<td align="left"><code>kappa</code>, <code>cohen_kappa</code></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">f1 score</td>
<td align="left"><code>f1_score</code></td>
<td align="center">×</td>
</tr>
<tr class="even">
<td align="left">false discovery rate</td>
<td align="left"><code>fdr</code>,
<code>false_discovery_rate</code></td>
<td align="center">×</td>
</tr>
<tr class="odd">
<td align="left">informedness</td>
<td align="left"><code>informedness</code></td>
<td align="center">×</td>
</tr>
<tr class="even">
<td align="left">markedness</td>
<td align="left"><code>markedness</code></td>
<td align="center">×</td>
</tr>
<tr class="odd">
<td align="left">Matthews’ correlation coefficient</td>
<td align="left"><code>mcc</code>,
<code>matthews_correlation_coefficient</code></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">negative predictive value</td>
<td align="left"><code>npv</code></td>
<td align="center">×</td>
</tr>
<tr class="odd">
<td align="left">positive predictive value</td>
<td align="left"><code>precision</code>, <code>ppv</code></td>
<td align="center">×</td>
</tr>
<tr class="even">
<td align="left">recall</td>
<td align="left"><code>recall</code>, <code>sensitivity</code>,
<code>tpr</code>, <code>true_positive_rate</code></td>
<td align="center">×</td>
</tr>
<tr class="odd">
<td align="left">specificity</td>
<td align="left"><code>specificity</code>, <code>tnr</code>,
<code>true_negative_rate</code></td>
<td align="center">×</td>
</tr>
<tr class="even">
<td align="left">Youden’s J</td>
<td align="left"><code>youden_j</code>, <code>youden_index</code></td>
<td align="center">×</td>
</tr>
</tbody>
</table>
<div id="area-under-the-receiver-operating-curve" class="section level2">
<h2>Area under the receiver-operating curve</h2>
<p>The area under the receiver-operating curve is quite literally that.
It is the area under the curve created by plotting the true positive
rate (sensitivity) against the false positive rate (1-specificity). TPR
and FPR are derived from a contingency table, which is created by
comparing predicted class probabilities against a threshold. The
receiver-operating curve is created by iterating over1 threshold values.
The AUC of a model that predicts perfectly is <span class="math inline">\(1.0\)</span>, while <span class="math inline">\(0.5\)</span> indicates predictions that are no
better than random.</p>
<p>The implementation in <code>familiar</code> does not use the ROC
curve to compute the AUC. Instead, an algebraic equation by <span class="citation">Hand and Till (2001)</span> is used. For
<code>multinomial</code> outcomes the AUC is computed for each pairwise
comparison of outcome classes, and averaged <span class="citation">(Hand
and Till 2001)</span>.</p>
</div>
<div id="brier-score" class="section level2">
<h2>Brier score</h2>
<p>The Brier score <span class="citation">(Brier 1950)</span> is a
measure of deviation of predicted probabilities from the ideal situation
where the probability for class <em>a</em> is <span class="math inline">\(1.0\)</span> if the observed class is <em>a</em>
and <span class="math inline">\(0.0\)</span> if it is not <em>a</em>.
Hence, it can be viewed as a measure of calibration as well. A value of
<span class="math inline">\(0.0\)</span> is optimal.</p>
<p>The implementation in <code>familiar</code> iterates over all outcome
classes in a one-versus-all approach, as originally devised by <span class="citation">Brier (1950)</span>. For <code>binomial</code>
outcomes, the score is divided by 2, so that it falls in the <span class="math inline">\([0.0, 1.0]\)</span> range.</p>
</div>
<div id="contingency-table-based-metrics" class="section level2">
<h2>Contingency table-based metrics</h2>
<p>A contingency table or confusion matrix displays the observed and
predicted classes. When dealing with two classes, e.g. <em>a</em> and
<em>b</em>, one of the classes is usually termed ‘positive’ and the
other ‘negative’. For example, let <em>b</em> be the ‘positive’ class.
Then we can define the following four categories:</p>
<ul>
<li>True positive (<span class="math inline">\(TP\)</span>): <em>b</em>
is predicted and observed.</li>
<li>True negative (<span class="math inline">\(TN\)</span>): <em>a</em>
is predicted and observed.</li>
<li>False negative (<span class="math inline">\(FN\)</span>): <em>b</em>
was observed, but <em>a</em> was predicted.</li>
<li>False positive (<span class="math inline">\(FP\)</span>): <em>a</em>
was observed, but <em>b</em> was predicted.</li>
</ul>
<p>A contingency table contains the occurrence of each of the four
cases. If a model is good, most samples will be either true positive or
true negative. Models that are not as good may have larger numbers of
false positives and/or false negatives.</p>
<p>Metrics based on the contingency table use two or more of the four
categories to characterise model performance. The extension from two
classes (<code>binomial</code>) to more (<code>multinomial</code>) is
often not trivial. For many metrics, <code>familiar</code> uses a
one-versus-all approach. Here, all classes are iteratively used as the
‘positive’ class, with the rest grouped as ‘negative’. Three options can
be used to obtain performance values for <code>multinomial</code>
problems, with an implementation similar to that of
<code>scikit.learn</code>:</p>
<ul>
<li><p><code>micro</code>: The number of true positives, true negatives,
false positives and false negatives are computed for each class
iteration, and then summed over all classes. The score is calculated
afterwards.</p></li>
<li><p><code>macro</code>: A score is computed for each class iteration,
and then averaged.</p></li>
<li><p><code>weighted</code>: A score is computed for each class
iteration, and the averaged with a weight corresponding to the number of
samples with the observed ‘positive’ class, i.e. the
prevalence.</p></li>
</ul>
<p>By default, <code>familiar</code> uses <code>macro</code>, but the
averaging procedure may be selected through appending
<code>_micro</code>, <code>_macro</code> or <code>_weighted</code> to
the name of the metric. For example, <code>recall_micro</code> will
compute the recall metric using <code>micro</code> averaging.</p>
<p>Averaging only applies to <code>multinomial</code> outcomes. No
averaging is performed for <code>binomial</code> problems with two
classes. In this case <code>familiar</code> will always consider the
second class level to correspond to the ‘positive’ class.</p>
<div id="accuracy" class="section level3">
<h3>Accuracy</h3>
<p>Accuracy quantifies the number of correctly predicted classes: <span class="math inline">\(s_{acc}=(TP + TN) / (TP + TN + FP + FN)\)</span>.
The extension to more than 2 classes is trivial. No averaging is
performed for the accuracy metric.</p>
</div>
<div id="balanced-accuracy" class="section level3">
<h3>Balanced accuracy</h3>
<p>Accuracy is known to be sensitive to imbalances in the class
distribution. A balanced accuracy was therefore defined <span class="citation">(Brodersen et al. 2010)</span>, which is the averaged
within-class true positive rate (also known as recall or sensitivity):
<span class="math inline">\(s_{bac}=0.5 (TP / (TP + FN) + TN / (TN +
FP))\)</span>.</p>
<p>The extension to more than 2 classes involves summation of in-class
true positive rate <span class="math inline">\(TP / (TP + FN)\)</span>
for each positive class and subsequent division by the number of
classes. No averaging is performed for balanced accuracy.</p>
</div>
<div id="balanced-error-rate" class="section level3">
<h3>Balanced error rate</h3>
<p>The balanced error rate is closely related to balanced accuracy,
i.e. instead of the in-class true positive rate, the in-class false
negative rate is used: <span class="math inline">\(s_{ber}=0.5 (FN / (TP
+ FN) + FP / (TN + FP))\)</span>.</p>
<p>The extension to more than 2 classes involves summation of in-class
false negative rate <span class="math inline">\(FN / (TP + FN)\)</span>
for each positive class and subsequent division by the number of
classes. No averaging is performed for balanced error rate.</p>
</div>
<div id="f1-score" class="section level3">
<h3>F1 score</h3>
<p>The F1 score is the harmonic mean of precision and sensitivity: <span class="math inline">\(s_{f1} = 2 \; TP / (2 \; TP + FP +
FN)\)</span>.</p>
<p>The metric is not invariant to class permutation. Averaging is
therefore performed for <code>multinomial</code> outcomes.</p>
</div>
<div id="false-discovery-rate" class="section level3">
<h3>False discovery rate</h3>
<p>The false discovery rate quantifies the proportion of false positives
among all predicted positives, i.e. the Type I error: <span class="math inline">\(s_{fdr} = FP / (TP + FP)\)</span>.</p>
<p>The metric is not invariant to class permutation. Averaging is
therefore performed for <code>multinomial</code> outcomes.</p>
</div>
<div id="informedness" class="section level3">
<h3>Informedness</h3>
<p>Informedness is a generalisation of Youden’s J statistic <span class="citation">(Powers 2011)</span>. Informedness can be extended to
multiple classes, and no averaging is therefore required.</p>
<p>For <code>binomial</code> problems, informedness and the Youden J
statistic are the same.</p>
</div>
<div id="cohens-kappa" class="section level3">
<h3>Cohen’s kappa</h3>
<p>Cohen’s kappa coefficient is a measure of correspondence between the
observed and predicted classes <span class="citation">(Cohen
1960)</span>. Cohen’s kappa coefficient is invariant to class
permutations and no averaging is performed for Cohen’s kappa.</p>
</div>
<div id="markedness" class="section level3">
<h3>Markedness</h3>
<p>Markedness is related to the precision or positive predictive value
<span class="citation">(Powers 2011)</span>.</p>
</div>
<div id="matthews-correlation-efficient" class="section level3">
<h3>Matthews correlation efficient</h3>
<p>Matthews’ correlation coefficient measures the correlation between
observed and predicted classes [Matthews1975-kh].</p>
<p>An extension to multiple classes, i.e. multinomial outcomes, was
devised by <span class="citation">Gorodkin (2004)</span>.</p>
</div>
<div id="negative-predictive-value" class="section level3">
<h3>Negative predictive value</h3>
<p>The negative predictive value (NPV) is the fraction of predicted
negative classes that were also observed to be negative: <span class="math inline">\(s_{npv} = TN / (TN + FN)\)</span>.</p>
<p>The NPV is not invariant to class permutations. Averaging is
performed for <code>multinomial</code> outcomes.</p>
</div>
<div id="positive-predictive-value" class="section level3">
<h3>Positive predictive value</h3>
<p>The positive predictive value (PPV) is the fraction of predicted
positive classes that were also observed to be positive: <span class="math inline">\(s_{ppv} = TP / (TP + FP)\)</span>.</p>
<p>The PPV is also referred to as precision. The PPV is not invariant to
class permutations. Averaging is performed for <code>multinomial</code>
outcomes. <code>micro</code>-averaging effectively computes the
accuracy.</p>
</div>
<div id="recall" class="section level3">
<h3>Recall</h3>
<p>Recall, also known as sensitivity or true positive rate, is the
fraction of observed positive classes that were also predicted to be
positive: <span class="math inline">\(s_{recall} = TP / (TP +
FN)\)</span>.</p>
<p>Recall is not invariant to class permutations and averaging is
performed for <code>multinomial</code> outcomes. Both <code>micro</code>
and <code>weighted</code> averaging effectively compute the
accuracy.</p>
</div>
<div id="specificity" class="section level3">
<h3>Specificity</h3>
<p>Specificity, also known as the true negative rate, is the fraction of
observed negative classes that were also predicted to be negative: <span class="math inline">\(s_{spec} = TN / (TN + FP)\)</span>.</p>
<p>Specificity is not invariant to class permutations and averaging is
performed for <code>multinomial</code> outcomes.</p>
</div>
<div id="youdens-j-statistic" class="section level3">
<h3>Youden’s J statistic</h3>
<p>Youden’s J statistic <span class="citation">(Youden 1950)</span> is
the sum of recall and specificity minus 1: <span class="math inline">\(s_{youden} = TP / (TP + FN) + TN / (TN + FP) -
1\)</span>.</p>
<p>Youden’s J statistic is not invariant to class permutations and
averaging is performed for <code>multinomial</code> outcomes.</p>
<p>For <code>binomial</code> problems, informedness and the Youden J
statistic are the same.</p>
</div>
</div>
</div>
<div id="regression-outcomes" class="section level1">
<h1>Regression outcomes</h1>
<p>Performance metrics for models with regression outcomes,
i.e. <code>count</code> and <code>continuous</code>, are listed
below.</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong>method</strong></th>
<th align="left"><strong>tag</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">explained variance</td>
<td align="left"><code>explained_variance</code></td>
</tr>
<tr class="even">
<td align="left">mean absolute error</td>
<td align="left"><code>mae</code>, <code>mean_absolute_error</code></td>
</tr>
<tr class="odd">
<td align="left">relative absolute error</td>
<td align="left"><code>rae</code>,
<code>relative_absolutive_error</code></td>
</tr>
<tr class="even">
<td align="left">mean log absolute error</td>
<td align="left"><code>mlae</code>,
<code>mean_log_absolute_error</code></td>
</tr>
<tr class="odd">
<td align="left">mean squared error</td>
<td align="left"><code>mse</code>, <code>mean_squared_error</code></td>
</tr>
<tr class="even">
<td align="left">relative squared error</td>
<td align="left"><code>rse</code>,
<code>relative_squared_error</code></td>
</tr>
<tr class="odd">
<td align="left">mean squared log error</td>
<td align="left"><code>msle</code>,
<code>mean_squared_log_error</code></td>
</tr>
<tr class="even">
<td align="left">median absolute error</td>
<td align="left"><code>medae</code>,
<code>median_absolute_error</code></td>
</tr>
<tr class="odd">
<td align="left">R<sup>2</sup> score</td>
<td align="left"><code>r2_score</code>, <code>r_squared</code></td>
</tr>
<tr class="even">
<td align="left">root mean square error</td>
<td align="left"><code>rmse</code>,
<code>root_mean_square_error</code></td>
</tr>
<tr class="odd">
<td align="left">root relative squared error</td>
<td align="left"><code>rrse</code>,
<code>root_relative_squared_error</code></td>
</tr>
<tr class="even">
<td align="left">root mean square log error</td>
<td align="left"><code>rmsle</code>,
<code>root_mean_square_log_error</code></td>
</tr>
</tbody>
</table>
<p>Each of the above metrics can be made more robust against rare
outliers by appending <code>_winsor</code> or <code>_trim</code> as a
suffix to the metric name. This respectively performs winsorising
(clipping) and trimming (truncating) based on the absolute prediction
error, prior to computing the metric. Winsorising clips the predicted
values for 5% of the instances with the most extreme absolute errors
prior to computing the performance metric, whereas trimming removes
these instances. For example, winsored and trimmed versions of the mean
squared error metric are specified as <code>mse_winsor</code> and
<code>mse_trim</code> respectively.</p>
<p>Let <span class="math inline">\(y\)</span> be the set of observed
values, and <span class="math inline">\(\hat{y}\)</span> the
corresponding predicted values. The error is then <span class="math inline">\(\epsilon = y-\hat{y}\)</span>.</p>
<div id="explained-variance" class="section level2">
<h2>Explained variance</h2>
<p>The explained variance is defined as <span class="math inline">\(1 -
\text{Var}\left(\epsilon\right) / \text{Var}\left(y\right)\)</span>.
This metric is not sensitive to differences in offset between observed
and predicted values.</p>
</div>
<div id="mean-absolute-error" class="section level2">
<h2>Mean absolute error</h2>
<p>The mean absolute error is defined as <span class="math inline">\(1/N
\sum_i^N \left|\epsilon_i\right|\)</span>, with <span class="math inline">\(N\)</span> the number of samples.</p>
</div>
<div id="relative-absolute-error" class="section level2">
<h2>Relative absolute error</h2>
<p>The relative absolute error is defined as <span class="math inline">\(\sum_i^N \left|\epsilon_i\right|/ \sum_i^N
\left|y_i - \bar{y}\right|\)</span>.</p>
</div>
<div id="mean-log-absolute-error" class="section level2">
<h2>Mean log absolute error</h2>
<p>The mean log absolute error is defined as <span class="math inline">\(1/N \sum_i^N \log(\left|\epsilon_i\right| +
1)\)</span>.</p>
</div>
<div id="mean-squared-error" class="section level2">
<h2>Mean squared error</h2>
<p>The mean squared error is defined as <span class="math inline">\(1/N
\sum_i^N \left(\epsilon_i \right)^2\)</span>.</p>
</div>
<div id="relative-squared-error" class="section level2">
<h2>Relative squared error</h2>
<p>The relative squared error is defined as <span class="math inline">\(\sum_i^N \left(\epsilon_i\right)^2/ \sum_i^N
\left(y_i - \bar{y}\right)^2\)</span>.</p>
</div>
<div id="mean-squared-log-error" class="section level2">
<h2>Mean squared log error</h2>
<p>Mean squared log error is defined as <span class="math inline">\(1/N
\sum_i^N \left(\log \left(y_i + 1\right) - \log\left(\hat{y}_i +
1\right)\right)^2\)</span>. Note that this score only applies to
observed and predicted values in the positive domain. It is not defined
for negative values.</p>
</div>
<div id="median-absolute-error" class="section level2">
<h2>Median absolute error</h2>
<p>The median absolute error is the median of absolute error <span class="math inline">\(\left|\epsilon\right|\)</span>.</p>
</div>
<div id="r2-score" class="section level2">
<h2>R<sup>2</sup> score</h2>
<p>The R<sup>2</sup> score is defined as: <span class="math display">\[R^2 = 1 -
\frac{\sum_i^N(\epsilon_i)^2}{\sum_i^N(y_i - \bar{y})^2}\]</span> Here
<span class="math inline">\(\bar{y}\)</span> denotes the mean value of
<span class="math inline">\(y\)</span>.</p>
</div>
<div id="root-mean-square-error" class="section level2">
<h2>Root mean square error</h2>
<p>The root mean square error is defined as <span class="math inline">\(\sqrt{1/N \sum_i^N \left(\epsilon_i
\right)^2}\)</span>.</p>
</div>
<div id="root-relative-squared-error" class="section level2">
<h2>Root relative squared error</h2>
<p>The root relative squared error is defined as <span class="math inline">\(\sqrt{\sum_i^N \left(\epsilon_i\right)^2/ \sum_i^N
\left(y_i - \bar{y}\right)^2}\)</span>.</p>
</div>
<div id="root-mean-square-log-error" class="section level2">
<h2>Root mean square log error</h2>
<p>The root mean square log error is defined as <span class="math inline">\(\sqrt{1/N \sum_i^N \left(\log \left(y_i + 1\right)
- \log\left(\hat{y}_i + 1\right)\right)^2}\)</span>. Note that this
score only applies to observed and predicted values in the positive
domain. It is not defined for negative values.</p>
</div>
</div>
<div id="survival-outcomes" class="section level1">
<h1>Survival outcomes</h1>
<p>Performance metrics for models with survival outcomes,
i.e. <code>survival</code>, are listed below.</p>
<table>
<colgroup>
<col width="56%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>method</strong></th>
<th align="left"><strong>tag</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">concordance index</td>
<td align="left"><code>concordance_index</code>, <code>c_index</code>,
<code>concordance_index_harrell</code>,
<code>c_index_harrell</code></td>
</tr>
</tbody>
</table>
<div id="concordance-index" class="section level2">
<h2>Concordance index</h2>
<p>The concordance index assesses ordering between observed and
predicted values. Let <span class="math inline">\(T\)</span> be observed
times, <span class="math inline">\(c\)</span> the censoring status
(<span class="math inline">\(0\)</span>: no observed event; <span class="math inline">\(1\)</span>: event observed) and <span class="math inline">\(\hat{T}\)</span> predicted times. Concordance
between all pairs of values is determined as follows <span class="citation">(Pencina and D’Agostino 2004)</span>:</p>
<ul>
<li>Concordant: a pair is concordant if <span class="math inline">\(T_i
&lt; T_j\)</span> and <span class="math inline">\(\hat{T}_i &lt;
\hat{T}_j\)</span> (provided <span class="math inline">\(c_i=1\)</span>), or if <span class="math inline">\(T_i &gt; T_j\)</span> and <span class="math inline">\(\hat{T}_i &gt; \hat{T}_j\)</span> (provided <span class="math inline">\(c_j=1\)</span>).</li>
<li>Discordant: a pair is discordant if <span class="math inline">\(T_i
&lt; T_j\)</span> and <span class="math inline">\(\hat{T}_i &gt;
\hat{T}_j\)</span> (provided <span class="math inline">\(c_i=1\)</span>), or if <span class="math inline">\(T_i &gt; T_j\)</span> and <span class="math inline">\(\hat{T}_i &lt; \hat{T}_j\)</span> (provided <span class="math inline">\(c_j=1\)</span>).</li>
<li>Tied: a pair is tied if <span class="math inline">\(\hat{T}_i =
\hat{T}_j\)</span>, provided that <span class="math inline">\(c_i=c_j=1\)</span>.</li>
<li>Not comparable: otherwise. This occurs, for example, if sample <span class="math inline">\(i\)</span> was censored before an event was
observed in sample <span class="math inline">\(j\)</span>, or both
samples were censored.</li>
</ul>
<p>The concordance index is then computed as: <span class="math display">\[ci = \frac{n_{concord} + 0.5
n_{tied}}{n_{concord} + n_{discord} + n_{tied}}\]</span></p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Brier1950-lo" class="csl-entry">
Brier, Glenn W. 1950. <span>“Verification of Forecasts Expressed in
Terms of Probability.”</span> <em>Mon. Weather Rev.</em> 78 (1): 1–3.
</div>
<div id="ref-Brodersen2010-vb" class="csl-entry">
Brodersen, K H, C S Ong, K E Stephan, and J M Buhmann. 2010. <span>“The
Balanced Accuracy and Its Posterior Distribution.”</span> In <em>2010
20th International Conference on Pattern Recognition</em>, 3121–24.
</div>
<div id="ref-Cohen1960-kc" class="csl-entry">
Cohen, Jacob. 1960. <span>“A Coefficient of Agreement for Nominal
Scales.”</span> <em>Educ. Psychol. Meas.</em> 20 (1): 37–46.
</div>
<div id="ref-Gorodkin2004-tx" class="csl-entry">
Gorodkin, J. 2004. <span>“Comparing Two k-Category Assignments by a
k-Category Correlation Coefficient.”</span> <em>Comput. Biol. Chem.</em>
28 (5-6): 367–74.
</div>
<div id="ref-Hand2001-ij" class="csl-entry">
Hand, David J, and Robert J Till. 2001. <span>“A Simple Generalisation
of the Area Under the <span>ROC</span> Curve for Multiple Class
Classification Problems.”</span> <em>Mach. Learn.</em> 45 (2): 171–86.
</div>
<div id="ref-Pencina2004-ii" class="csl-entry">
Pencina, Michael J, and Ralph B D’Agostino. 2004. <span>“Overall
<span>C</span> as a Measure of Discrimination in Survival Analysis:
Model Specific Population Value and Confidence Interval
Estimation.”</span> <em>Stat. Med.</em> 23 (13): 2109–23.
</div>
<div id="ref-Powers2011-jt" class="csl-entry">
Powers, David Martin. 2011. <span>“Evaluation: From Precision, Recall
and f-Measure to <span>ROC</span>, Informedness, Markedness and
Correlation.”</span> <em>International Journal of Machine Learning
Technology</em> 2 (1): 37–63.
</div>
<div id="ref-Youden1950-no" class="csl-entry">
Youden, W J. 1950. <span>“Index for Rating Diagnostic Tests.”</span>
<em>Cancer</em> 3 (1): 32–35.
</div>
</div>
</div>

<div class="footer">
<br>
<a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFgAAAAfCAMAAABUFvrSAAAAIGNIUk0AAHolAACAgwAA+f8AAIDpAAB1MAAA6mAAADqYAAAXb5JfxUYAAAAEZ0FNQQAAsY58+1GTAAAAAXNSR0IB2cksfwAAAW5QTFRF////////////////7+/v39/f1tXV09bS0tXS0tXR0dTR0dTQ0NTQ0NPPz9PPztLOztHNzdHNzdHMz8/PzdDMzNDMzNDLzM/Ly8/Ly8/Ky87Kys3Jyc3Jyc3IyMzIyMzHx8vHxsrGxsrFxcnFxcnExMnExMjDw8jDxMfDw8fCwsfCwcXAwMXAwMW/wMS/v8S+v8O+vsO+vsK9vcK9vcK8v7+/vMG8vMG7vMC8u8C7u8C6ur+6ur+5ub65ub64uL23t7y2tru1tbq0tLqztLmzs7iysrixsrexsbewsbawsLavsLWvr7Wur7SusLOvrrStrrOtr7KvrbOsrLKrr6+vq7Gqn6OenqCdn5+flpmWk5iTkZSRkZORj4+PiYyJhIaEhIWEgoWCgICAfX98fH98eXx5cHJvcHBwYGBgXV5dUFFQUFBQQ0RDQEBAPj8+NTY1MjMxMDAwKSkpKCkoICAgGxsbEBAQDg4ODQ4NAAAAlzoSDQAAAAN0Uk5TAAoO5yEBUwAAAvhJREFUeNq1lutX2kAQxWmXFDVGYy1EIjQ2VZDiu1CsRQQURYvV+qSKj6II8rANYOT+9z0JqIASo9Y5ydkP2f2d2Ts7d2N4jRcJgwEIBwO+SbdTFGw8ZzZz1n5BdLgnfLPBcCT6fW1jY3P78QEYEA76PWMu0W5lGbrNZGrrYNg+u+ga9fgVcmxtY/NJZAOCfs+IY4Bn6eN8RdlEJX9Ed1uFIfdnfzC8uBJbv5tyqqhMLKa0wQHPiEOwMInLW4Eu9xmzfdDtmQ0uLK3cSXmvBBTS6QJQ2tMC+8YcgpnOApAzSa83mZEBZIff2odGfYFQJNqc8s4VchQhhFA5XO1pgCddAxaFKyeNpBpxGSgNmwXXxMxcWE25fkkJGUIIoExESQPsFnkmC0gUuQmjBGQZq+j2BEKR5dUGLVLIvbkGkxxSrcHO92wCkIyENJL3u+2O8Zng/FJsvR5cRF0GFIqtwaKVvoTcSxrCKOOS7hPdXwLhxUYtUFC+Z6AKQgpoDRZ6joEkaYo4cMQKril/KLLcCE4TVYmqFmkNsK0rD9lIiDdXKCSrwwEhREae6Ve0WIiuPg3M0xVlW171BBe21CGjbLbSYR0c/To3H409TQquHTggREKZ8pbjEiRqqxxXtWjjRLdvLrzUAK4Vr5qwZvEsJsCrzExWF9Tk9gIm84e74BRyRN9xeyS4vkHSmg1yK4Wxt5yUIClDayn0t3SteLWq3RQvjQrN31O87e2dEiBl0tJDJmTrykImN8dtq6AOpIw8Y3OMf2s+bvptU+hJqFrc1yCfpmZDkWYX0mv0H9WWpvS2tH6w8z27e58JJVi7c2ImuNBkQvrBOOWZc0CqsyFKtU3+97OuaQBnXGe90RuTMvCHtpziuWCcmDvPm64m+t2vlmuq/YHqqwnGCcfs1l+mCcbSmgtSe8iDGQNnPEsnrq//fZrltXS4tk3oAOPvT2tPF91uMrXTDNv340JrjQ4hbsHAxeE0z1ksHD99eKFdl0dl/P//Cl+9EPcfS+yBAoqk3eUAAAAASUVORK5CYII=" /></a>
This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Cite as: Alex Zwanenburg. familiar: Vignettes and Documentation (2021). <a href="https://github.com/alexzwanenburg/familiar">https://github.com/alexzwanenburg/familiar</a>
</div>


<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
